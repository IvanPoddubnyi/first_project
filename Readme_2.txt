Описание проекта:
Дано: Два множества объектов: A и B. Каждый объект в множества описывается какими-то признаками.
Желаемый результат: Для каждого объекта из множества A найти один или несколько объектов из B, которые близки к нему по некоторой заданной метрике.
Исходные данные
base.csv - анонимизированный набор товаров. Каждый товар представлен как уникальный id (0-base, 1-base, 2-base) и вектор признаков размерностью 72.
train.csv - обучающий датасет. Каждая строчка - один товар, для которого известен уникальный id (0-query, 1-query, …) , вектор признаков И id товара из base.csv, который максимально похож на него (по мнению экспертов).
validation.csv - датасет с товарами (уникальный id и вектор признаков), для которых надо найти наиболее близкие товары из base.csv
validation_answer.csv - правильные ответы к предыдущему файлу.
План выполнения работы:
1.	Загрузка и ознакомление с данными.
1.1. Предварительная обработка,
1.2. Полноценный разведочный анализ,
1.3. Проверка на мультиколлинеарность,
1.4 Масштабирование признаков
2.	Масштабирование признаков
3.	Kmeans + самописная реализация KNN
4 Faiss 4.1 Подготовка исходных данных
4.2 Настройка модели и определение оптимальных парамтеров на тестовой выборке
4.3 Получение значения метрики accuracy@5 на валидационной выборке
4.4 Предсказание товаров для validation
5.	Вывод по работе.
 
Вывод по работе
1.	Исследовательский анализ данных.
•	Проведен EDA для исходных датасетов
•	в датасетах большинство признаков имеет нормальное распределение.
•	В датасетах выявлено ряд признаков, которые имеют равномерное распределение (+/- 10 % от среднего уровня). Такие столбцы были удалены из дальнейшего расмотрения в целях экономии ресурсов.
•	В датасетах ряд столбцов имеют распределение, которое отличается тем, что одно из значений существенно преобладает над остальными, и доля этих значений более 70 или 80 %. Такие столбцы не принесут существенной информации, так как доля оставшихся значений не существенна. Даныне столбцы могут быть удалены из расмотрения.
•	Датасеты очищено от выбросов. Критерием было выход за границы трех сигма. В датасетах примерное количество выбрасов порядка 15 %. Очищены датасеты base и train. Датасет validation оставлен без изменений.
•	Признаки датасета являются не скоррелированными. Значения корреляции Пирсона не существенны. Оценка проводилась на датасете train, являющегося случайной выборкой из base. Коэффициент корреляция Пирсона использован в целях сокращения времени, целесообразность использования данного коэффициента обосновывается тем, что признаки распределены по нормальному закону, очищены от выбросов и признаки только числовые.
2.	Построена модель на основе комбинации Kmeans для кластеризации датасета base и самописной реализацией алгоритма ближайших соседей.
•	Датасет base разбит на кластеры с помощью алгоритма Kmeans. C помощью библиотеки Yellowbrick по методу "локтя" определено оптимальное значение числа кластеров. Проанализирована влияние объема обучающего датасета на оптимальное количество кластеров разбиения.
•	Далее для каждого исследуемого датасета определяет ближайших центроид кластера по расстоянию евклида, а затем отбирает ближайшие продуктя из этого кластера.
•	Алгоритм показал значение метрики accuracy@5 более 50 % для обучающей и тестовой выборки.
•	алгоритм оказался очень медленным, и расчет метрики пришлось ограничить 1000 товаров, при том, что рекомендации для этих товаров подбираются более 1 часа.
•	медленное время выполнения алгорится не позволяет его использовать и требуется его дальнейшая оптимизация. (Например KNN от sklearn)
3.	Рассмотрена работа библиотеки faiss для данной задачи.
•	библиотека позволяет существенно сократить время поиска похожих товаров, в разы по сравнению с базовым подходом.
•	проанализированны влияние различных скейлеров, числа кластеров и объемов обучающей выборки на значение метрики.
•	наибольшее значение метрики accuracy@5 достигается при использовании скейлера - StandardScaler. Средние результаты целевой метрики, полученные для скейлеров RobustScaler и StandardScaler практически идентичны.
•	влияние количества кластеров или объем выборки для обучения модели можно оценить в 1 %.
•	значение метрики, полученной на валидационной выборке, составляет - 52.5 %.
•	получен список наиболее похожих товаров для валидационнной выборки.
4.	В данной работе модель построенная на faiss может быть улучшена, так как не все возможные параметры настройки модели (такие как способ определения расстояния между векторами, index) были проанализированы и оптимизированы.
